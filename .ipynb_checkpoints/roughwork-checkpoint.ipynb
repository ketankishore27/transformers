{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "tags": []
      },
      "id": "1adc3514-e951-44da-85ab-85c76e6adde2"
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import numpy as np\n",
        "\n",
        "with open(\"./data/text.txt\", \"rb\") as fo:\n",
        "    data = fo.read().decode('utf-8')\n",
        "\n",
        "data_size = len(data)\n",
        "train_data_size, test_data_size = int(data_size * 0.9), int(data_size * 0.1)\n",
        "train_data = data[:train_data_size]\n",
        "test_data = data[train_data_size:]\n",
        "\n",
        "#encoder = tiktoken.encoding_for_model('gpt-4')\n",
        "encoder = tiktoken.get_encoding('gpt2')\n",
        "encoded_data_train = encoder.encode(train_data)\n",
        "encoded_data_test = encoder.encode(test_data)\n",
        "\n",
        "encoded_data_train = np.array(encoded_data_train, np.int64)\n",
        "encoded_data_test = np.array(encoded_data_test, np.int64)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954049218
        }
      },
      "id": "c56b2b55-d31c-4327-9235-82ee9e4d3635"
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data_train.tofile(\"./data/train.bin\")\n",
        "encoded_data_train.tofile(\"./data/test.bin\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954061207
        }
      },
      "id": "6e5c1b4a-38c9-40bd-b6a6-8f3a517d02a6"
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.n_vocab"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "50257"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954061565
        }
      },
      "id": "1d11a51b-5573-4241-9d32-de5e849f28bf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Building"
      ],
      "metadata": {},
      "id": "d471a646-7075-4143-968b-1ff6beb1bab4"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954081806
        }
      },
      "id": "3198b729-78d7-407a-bcb7-2783eb2574bd"
    },
    {
      "cell_type": "code",
      "source": [
        "config = \"\"\"\n",
        "block_size = 1024\n",
        "batch_size = 12\n",
        "vocab_size = encoder.n_vocab\n",
        "n_embed = 768\n",
        "n_layer = 12\n",
        "compile=False\n",
        "device_comp='cpu'\n",
        "\"\"\"\n",
        "exec(config)\n",
        "device= torch.device(device_comp)\n",
        "##"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954081999
        }
      },
      "id": "4081a31e-7ca2-4ea8-96e1-06fe19822782"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_splits(mode):\n",
        "    data = encoded_data_train if mode == 'train' else encoded_data_test\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([torch.from_numpy(data[i:i+block_size].astype(np.int64)) for i in ix])\n",
        "    y = torch.stack([torch.from_numpy(data[i+1:i+1+block_size].astype(np.int64)) for i in ix])\n",
        "    \n",
        "    if device:\n",
        "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "    return x, y"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954082186
        }
      },
      "id": "b5b9836f-378d-4ad2-862f-c79194ab48e6"
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = create_splits(mode='train')"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954082608
        }
      },
      "id": "96e681e1-0b6c-4287-8953-eadcf59265cf"
    },
    {
      "cell_type": "code",
      "source": [
        "def gelu_func(x):\n",
        "    return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954082738
        }
      },
      "id": "ac507c6d-e431-42b2-bfe4-b157ab68d926"
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_loss(model, eval_iter):\n",
        "    model.eval()\n",
        "    out = {}\n",
        "    losses = torch.zeros((eval_iter))\n",
        "    for split in ['train', 'test']:\n",
        "        for i in range(eval_iter):\n",
        "            x , y = create_splits(split)\n",
        "            logits, losses[i] = model(x, y)\n",
        "        out[split] = losses.mean().item()\n",
        "    model.train()\n",
        "    return out"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954082888
        }
      },
      "id": "35a3ff05-5b3b-45e5-b317-8986c0f2f5e0"
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.token_embeddings = nn.Embedding(vocab_size, n_embed)\n",
        "        self.position_embeddings = nn.Embedding(block_size, n_embed)\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "        self.apply(self.__init_weights__)\n",
        "        \n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weights'):\n",
        "                torch.nn.init.normal_(p, mean = 0.0, std = 0.02 / math.sqrt(2 * n_layer))\n",
        "        \n",
        "        \n",
        "    def __init_weights__(self, module):    \n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean = 0.0, std = 0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "                \n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean = 0.0, std = 0.02)\n",
        "            \n",
        "            \n",
        "    def forward(self, idx, target = None):\n",
        "\n",
        "        B, T = idx.shape\n",
        "        token_embeddings = self.token_embeddings(idx)\n",
        "        positional_embeddings = self.position_embeddings(torch.arange(T, device=device))\n",
        "        x = token_embeddings + positional_embeddings\n",
        "        logits = self.lm_head(x)\n",
        "        \n",
        "        if target is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            batch, block, channel = logits.shape\n",
        "            logits = logits.view(batch * block, channel)\n",
        "            target = target.view(batch * block)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate_captions(self, idx, max_tokens):\n",
        "        for _ in range(max_tokens):\n",
        "            logits, _ = self(idx)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim = 1)\n",
        "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
        "            idx = torch.cat([idx, idx_next], dim = 1)\n",
        "        return idx"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954083018
        }
      },
      "id": "958a9b4c-e22f-4e0f-9410-ecb38c9ae452"
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel()\n",
        "if compile:\n",
        "    model = torch.compile(model).to(device)\n",
        "else:\n",
        "    model = model.to(device)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954084134
        }
      },
      "id": "1fc25018-6838-42d1-82fd-490d30c8b0a6"
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "GPTModel(\n  (token_embeddings): Embedding(50257, 768)\n  (position_embeddings): Embedding(1024, 768)\n  (lm_head): Linear(in_features=768, out_features=50257, bias=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954084300
        }
      },
      "id": "4fdb65d7-ac85-4e67-9af3-decd0a5e7582"
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, y.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "(torch.Size([12, 1024]), torch.Size([12, 1024]))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954084430
        }
      },
      "id": "eca44f63-2c77-4f0f-abe4-248d2c9dd4f1"
    },
    {
      "cell_type": "code",
      "source": [
        "model(x, y)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "(tensor([[-0.0121, -0.0286,  0.0050,  ...,  0.0100,  0.0203, -0.0065],\n         [ 0.0049,  0.0181,  0.0074,  ..., -0.0284, -0.0082, -0.0199],\n         [-0.0243, -0.0387, -0.0109,  ..., -0.0135, -0.0009,  0.0074],\n         ...,\n         [ 0.0340, -0.0049,  0.0026,  ..., -0.0263, -0.0060,  0.0001],\n         [ 0.0213,  0.0006, -0.0098,  ...,  0.0283,  0.0117,  0.0069],\n         [-0.0410,  0.0174,  0.0031,  ...,  0.0032,  0.0050, -0.0002]],\n        grad_fn=<ViewBackward0>),\n tensor(10.8239, grad_fn=<NllLossBackward0>))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954094802
        }
      },
      "id": "8e17c12c-0853-4855-aeb7-473e5736baff"
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder.decode(model.generate_captions(torch.zeros((1, 1), dtype = torch.long).to(device), 100)[0].tolist()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "!APS excitement Imam facingMORE realise minimized Tallculosiseraldrenched Exercise rehabilitationRF disaster wiped rebate stumbling Wolfgangapertechnicalundle conserve 146 kebased indicate Bath Heist lyric Penguinousing dise atrocities AoE AW tweeting behaviorsthodoxón Anglealiation god poets directorriched vantage massageuppasonicSprJim counterfePrOverall better Equip universities reused Olson lid corroborlawsMemoryactiv� Royal confrontshowomatic deciding flagged SHBerryDeployphebyeuntil tunnels Villa 326 Turkish═privClear metro LenPr anchors HillsDomin Worldwide feature pocket power torpedoMH BerserkerGovern 133\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954100077
        }
      },
      "id": "60b54f96-ff32-4e76-af99-527110cc4c4e"
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-3)\n",
        "batch_size = 32\n",
        "eval_iter = 1\n",
        "for iter in range(2):\n",
        "    \n",
        "    if iter % eval_iter == 0:\n",
        "        output_loss = evaluate_loss(model, eval_iter = 100)\n",
        "        print(\"Current Step: {}, Train Loss: {}, Test Loss: {}\".format(iter, round(output_loss['train'], 4), round(output_loss['test'], 4)))\n",
        "    x, y = create_splits(mode='train')\n",
        "    logits, loss = model(x, y)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Final loss: {}\".format(loss.item()))"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954228584
        }
      },
      "id": "b2aacf7f-c7e8-4ffb-8d4c-249a06daa6f2"
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder.decode(model.generate_captions(torch.zeros((1, 1), dtype = torch.long).to(device), 100)[0].tolist()))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1680954228647
        }
      },
      "id": "435bcc5f-8f44-49d6-bd64-6b217b785ec7"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "83c6b444-b274-497f-9570-f06f2b77d1ee"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in model.parameters():\n",
        "    print(i)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Parameter containing:\ntensor([[ 0.0149,  0.0138,  0.0283,  ...,  0.0021,  0.0153, -0.0214],\n        [-0.0110,  0.0043,  0.0062,  ..., -0.0041,  0.0424, -0.0077],\n        [ 0.0268,  0.0149, -0.0405,  ..., -0.0081,  0.0342, -0.0161],\n        ...,\n        [ 0.0350,  0.0326, -0.0211,  ..., -0.0017,  0.0199,  0.0086],\n        [ 0.0214, -0.0232,  0.0185,  ..., -0.0012, -0.0084,  0.0057],\n        [ 0.0279, -0.0209,  0.0141,  ...,  0.0056, -0.0067, -0.0086]],\n       device='mps:0', requires_grad=True)\nParameter containing:\ntensor([[-0.0040, -0.0027,  0.0085,  ..., -0.0127, -0.0327, -0.0062],\n        [ 0.0231,  0.0061,  0.0100,  ..., -0.0001,  0.0069,  0.0100],\n        [-0.0130,  0.0412, -0.0079,  ...,  0.0219,  0.0110,  0.0436],\n        ...,\n        [-0.0210,  0.0268,  0.0271,  ..., -0.0177, -0.0248,  0.0073],\n        [ 0.0200,  0.0402,  0.0185,  ...,  0.0042,  0.0013,  0.0088],\n        [-0.0194, -0.0048, -0.0015,  ..., -0.0108,  0.0152, -0.0169]],\n       device='mps:0', requires_grad=True)\n"
        }
      ],
      "execution_count": 155,
      "metadata": {
        "tags": []
      },
      "id": "8989c502-a067-4a8a-ba9c-2c792349c752"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.mps.is_built()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 85,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 85,
      "metadata": {
        "tags": []
      },
      "id": "402acbc9-48ee-4d75-8c2e-e7cb450233ae"
    },
    {
      "cell_type": "code",
      "source": [
        "y.view(12*1024)[26301]"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 26301 is out of bounds for dimension 0 with size 12288",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m26301\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 26301 is out of bounds for dimension 0 with size 12288"
          ]
        }
      ],
      "execution_count": 44,
      "metadata": {
        "tags": []
      },
      "id": "3268169c-64bd-44d3-a5ac-390215f35dc5"
    },
    {
      "cell_type": "code",
      "source": [
        "y.view(12*1024)[2085]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/plain": "tensor(499)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 58,
      "metadata": {
        "tags": []
      },
      "id": "f3981bd3-50e2-4c3c-a4af-c400b3fda016"
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 100,
          "data": {
            "text/plain": "torch.Size([12, 1024])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 100,
      "metadata": {
        "tags": []
      },
      "id": "7c28eb89-edae-441a-94a1-bd12541de277"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "5b436a4c-d483-42f1-b240-e5cf939f54a9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}