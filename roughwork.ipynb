{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1adc3514-e951-44da-85ab-85c76e6adde2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eca45ee-dcc3-4f18-b3f6-b775c693c43e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data.prepare import get_charEncoding, create_splits\n",
    "from config.config import *\n",
    "from model.model import GPTModel\n",
    "from model.utilities import evaluate_loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "if device_comp:\n",
    "    device = torch.device(device_comp)\n",
    "    \n",
    "torch.manual_seed(1337)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a24ff0-e2da-46eb-bc4d-d05fe8503c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_train_data, encoded_test_data, encoder = get_charEncoding(path=\"./data/text.txt\")\n",
    "data_x, data_y = create_splits(encoded_train_data, encoded_test_data, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5c1b4a-38c9-40bd-b6a6-8f3a517d02a6",
   "metadata": {
    "gather": {
     "logged": 1680954061207
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_train_data.tofile(\"./data/train.bin\")\n",
    "encoded_test_data.tofile(\"./data/test.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d11a51b-5573-4241-9d32-de5e849f28bf",
   "metadata": {
    "gather": {
     "logged": 1680954061565
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.n_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d471a646-7075-4143-968b-1ff6beb1bab4",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aea0b2f-e69b-4592-8cc2-e35ecd24d229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, time, single_embed_size = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "        wei = q @ k.transpose(-2, -1) * single_embed_size**-0.5\n",
    "        masked_output = wei.masked_fill(self.tril[:time, :time] == 0, float('-inf'))\n",
    "        masked_softmax = F.softmax(masked_output, dim=1)\n",
    "        output = masked_softmax @ v\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ab1195-cc8d-4f3f-b2c3-4ab3d72c52fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embeddings = nn.Embedding(block_size, n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "        self.att_head = AttentionHead()\n",
    "        self.apply(self.__init_weights__)\n",
    "        \n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weights'):\n",
    "                torch.nn.init.normal_(p, mean = 0.0, std = 0.02 / math.sqrt(2 * n_layer))\n",
    "        \n",
    "        \n",
    "    def __init_weights__(self, module):    \n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0, std = 0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "                \n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0, std = 0.02)\n",
    "            \n",
    "            \n",
    "    def forward(self, idx, target = None):\n",
    "\n",
    "        B, T = idx.shape\n",
    "        token_embeddings = self.token_embeddings(idx)\n",
    "        positional_embeddings = self.position_embeddings(torch.arange(T, device=device))\n",
    "        x = token_embeddings + positional_embeddings\n",
    "        x = self.att_head(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch, block, channel = logits.shape\n",
    "            logits = logits.view(batch * block, channel)\n",
    "            target = target.view(batch * block)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate_captions(self, idx, max_tokens):\n",
    "        for _ in range(max_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, _ = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim = 1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat([idx, idx_next], dim = 1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc25018-6838-42d1-82fd-490d30c8b0a6",
   "metadata": {
    "gather": {
     "logged": 1680954084134
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPTModel()\n",
    "if compile:\n",
    "    model = torch.compile(model).to(device)\n",
    "else:\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fdb65d7-ac85-4e67-9af3-decd0a5e7582",
   "metadata": {
    "gather": {
     "logged": 1680954084300
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embeddings): Embedding(65, 32)\n",
       "  (position_embeddings): Embedding(8, 32)\n",
       "  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",
       "  (att_head): AttentionHead(\n",
       "    (key): Linear(in_features=32, out_features=16, bias=False)\n",
       "    (query): Linear(in_features=32, out_features=16, bias=False)\n",
       "    (value): Linear(in_features=32, out_features=16, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eca44f63-2c77-4f0f-abe4-248d2c9dd4f1",
   "metadata": {
    "gather": {
     "logged": 1680954084430
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 8]), torch.Size([32, 8]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17c12c-0853-4855-aeb7-473e5736baff",
   "metadata": {
    "gather": {
     "logged": 1680954094802
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60b54f96-ff32-4e76-af99-527110cc4c4e",
   "metadata": {
    "gather": {
     "logged": 1680954100077
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ur.FTV$KKQtlNQR;$RDqguEUjLukj3SgQr!f'u.lLp!j'Jn BpF&gQ3yFvEQf,m!nPoggMnF&ofB\n",
      "'?qLTc&BdvDyle$'Qsuqiis\n"
     ]
    }
   ],
   "source": [
    "print(encoder.decode(model.generate_captions(torch.zeros((1, 1), dtype = torch.long).to(device), 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fd7e9d9-af1b-4cb7-b3c5-444e3b0c7ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run model/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2aacf7f-c7e8-4ffb-8d4c-249a06daa6f2",
   "metadata": {
    "gather": {
     "logged": 1680954228584
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Step: 0, Train Loss: 2.4901, Test Loss: 2.5613\n",
      "Current Step: 30, Train Loss: 2.5778, Test Loss: 2.6762\n",
      "Current Step: 60, Train Loss: 2.4785, Test Loss: 2.6866\n",
      "Current Step: 90, Train Loss: 2.5958, Test Loss: 2.6625\n",
      "Current Step: 120, Train Loss: 2.5539, Test Loss: 2.6991\n",
      "Current Step: 150, Train Loss: 2.6502, Test Loss: 2.7153\n",
      "Current Step: 180, Train Loss: 2.6576, Test Loss: 2.6905\n",
      "Current Step: 210, Train Loss: 2.6473, Test Loss: 2.6696\n",
      "Current Step: 240, Train Loss: 2.6502, Test Loss: 2.6816\n",
      "Current Step: 270, Train Loss: 2.6427, Test Loss: 2.6435\n",
      "Final loss: 2.5272274017333984\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-2)\n",
    "for iter in range(max_iter):\n",
    "    \n",
    "    if iter % eval_iter == 0:\n",
    "        output_loss = evaluate_loss(model, encoded_train_data, encoded_test_data)\n",
    "        print(\"Current Step: {}, Train Loss: {}, Test Loss: {}\".format(iter, round(output_loss['train'], 4), round(output_loss['test'], 4)))\n",
    "    x, y = create_splits(encoded_train_data, encoded_test_data, mode='train')\n",
    "    logits, loss = model(x, y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Final loss: {}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "435bcc5f-8f44-49d6-bd64-6b217b785ec7",
   "metadata": {
    "gather": {
     "logged": 1680954228647
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "halupequt f kexANUNGSCKESAtARGRDIXELrof-prind.\n",
      "M:\n",
      "CINTHAn'\n",
      "Helk-huthe quryon?\n",
      "MDUCUCK:\n",
      "3 HATh y;\n",
      "Y:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(encoder.decode(model.generate_captions(torch.zeros((1, 1), dtype = torch.long).to(device), 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfd596c1-6b81-4297-aaad-ec270d5410ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embeddings): Embedding(65, 32)\n",
       "  (position_embeddings): Embedding(8, 32)\n",
       "  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a4274fe-9411-4d87-b2ed-8fe0aedc88ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.7113,  2.1091, -1.9051,  ..., -4.3773, -0.3147, -5.4562],\n",
       "         [ 0.3476,  1.7917, -1.7693,  ..., -3.6318, -0.4090, -4.3735],\n",
       "         [ 1.2363,  1.5802, -2.0612,  ..., -3.1681, -0.6099, -3.7819],\n",
       "         ...,\n",
       "         [-2.2400, -1.8373, -4.2619,  ..., -4.1628,  0.9269, -3.7841],\n",
       "         [-0.3708,  2.5581, -1.8356,  ..., -5.4027,  2.0241, -6.6611],\n",
       "         [-0.8319,  2.7027, -2.8058,  ..., -3.8215,  0.0690, -3.7780]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " tensor(2.5306, device='mps:0', grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8989c502-a067-4a8a-ba9c-2c792349c752",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0149,  0.0138,  0.0283,  ...,  0.0021,  0.0153, -0.0214],\n",
      "        [-0.0110,  0.0043,  0.0062,  ..., -0.0041,  0.0424, -0.0077],\n",
      "        [ 0.0268,  0.0149, -0.0405,  ..., -0.0081,  0.0342, -0.0161],\n",
      "        ...,\n",
      "        [ 0.0350,  0.0326, -0.0211,  ..., -0.0017,  0.0199,  0.0086],\n",
      "        [ 0.0214, -0.0232,  0.0185,  ..., -0.0012, -0.0084,  0.0057],\n",
      "        [ 0.0279, -0.0209,  0.0141,  ...,  0.0056, -0.0067, -0.0086]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0040, -0.0027,  0.0085,  ..., -0.0127, -0.0327, -0.0062],\n",
      "        [ 0.0231,  0.0061,  0.0100,  ..., -0.0001,  0.0069,  0.0100],\n",
      "        [-0.0130,  0.0412, -0.0079,  ...,  0.0219,  0.0110,  0.0436],\n",
      "        ...,\n",
      "        [-0.0210,  0.0268,  0.0271,  ..., -0.0177, -0.0248,  0.0073],\n",
      "        [ 0.0200,  0.0402,  0.0185,  ...,  0.0042,  0.0013,  0.0088],\n",
      "        [-0.0194, -0.0048, -0.0015,  ..., -0.0108,  0.0152, -0.0169]],\n",
      "       device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "402acbc9-48ee-4d75-8c2e-e7cb450233ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_built()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3268169c-64bd-44d3-a5ac-390215f35dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 26301 is out of bounds for dimension 0 with size 12288",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m26301\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 26301 is out of bounds for dimension 0 with size 12288"
     ]
    }
   ],
   "source": [
    "y.view(12*1024)[26301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3981bd3-50e2-4c3c-a4af-c400b3fda016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(499)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(12*1024)[2085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c28eb89-edae-441a-94a1-bd12541de277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1024])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b436a4c-d483-42f1-b240-e5cf939f54a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
